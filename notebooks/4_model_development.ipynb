{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c309b15c",
   "metadata": {},
   "source": [
    "# Diabetes Prediction Model Development \n",
    "This notebook documents the development of a machine learning pipeline for predicting diabetes. The workflow includes:\n",
    "\n",
    "1. **Data Loading and Preparation**: Loading the engineered dataset and splitting it into features and target variables.\n",
    "2. **Model Definition**: Defining a variety of machine learning models, including:\n",
    "    - Decision Tree\n",
    "    - Random Forest\n",
    "    - Gradient Boosting\n",
    "    - Support Vector Machine (SVM)\n",
    "    - K-Nearest Neighbors (KNN)\n",
    "    - Naive Bayes\n",
    "    - Logistic Regression\n",
    "    - XGBoost\n",
    "3. **Model Evaluation**: Using cross-validation to evaluate models based on metrics such as accuracy, precision, recall, and F1 score.\n",
    "4. **Detailed Analysis**: Performing a detailed evaluation of the top 3 models, including confusion matrices, ROC curves, and precision-recall curves.\n",
    "5. **Feature Importance**: Analyzing feature importance for the best-performing model.\n",
    "6. **Summary and Next Steps**: Summarizing findings and outlining next steps for further development.\n",
    "\n",
    "The goal is to identify the best-performing model for predicting diabetes and to provide insights into the most important features contributing to the predictions.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b62a0856",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, StratifiedKFold\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "from sklearn.metrics import confusion_matrix, classification_report, roc_curve, auc, precision_recall_curve\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from xgboost import XGBClassifier\n",
    "import joblib\n",
    "import os\n",
    "\n",
    "# Set styling for plots\n",
    "plt.style.use('seaborn-v0_8-whitegrid')\n",
    "sns.set_palette('viridis')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fc92a51b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading engineered diabetes dataset...\n"
     ]
    }
   ],
   "source": [
    "# 1. Load the Engineered Dataset\n",
    "# -----------------------------------------------------\n",
    "\n",
    "print(\"Loading engineered diabetes dataset...\")\n",
    "df = pd.read_csv('C:/Users/hp/Desktop/diabetes-analysis-project/outputs/features_engineered_scaled.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0a1f420f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Preparing Data for Modeling:\n",
      "Features: ['Pregnancies', 'Glucose', 'BloodPressure', 'SkinThickness', 'Insulin', 'BMI', 'DiabetesPedigreeFunction', 'Age', 'Diabetes_Risk_Index', 'Insulin_Sensitivity', 'Age_BMI_Factor']\n",
      "Target: Outcome (Diabetes = 1, No Diabetes = 0)\n",
      "Training set: 741 samples\n",
      "Testing set: 248 samples\n",
      "\n",
      "Class distribution:\n",
      "Training set: Outcome\n",
      "1    50.1\n",
      "0    49.9\n",
      "Name: proportion, dtype: float64%\n",
      "Testing set: Outcome\n",
      "0    50.0\n",
      "1    50.0\n",
      "Name: proportion, dtype: float64%\n"
     ]
    }
   ],
   "source": [
    "# 2. Prepare Data for Modeling\n",
    "\n",
    "print(\"\\n Preparing Data for Modeling:\")\n",
    "\n",
    "# Split features and target\n",
    "X = df.drop('Outcome', axis=1)\n",
    "y = df['Outcome']\n",
    "\n",
    "print(f\"Features: {X.columns.tolist()}\")\n",
    "print(f\"Target: Outcome (Diabetes = 1, No Diabetes = 0)\")\n",
    "\n",
    "# Split data into training and testing sets (stratified by outcome)\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.25, random_state=42, stratify=y\n",
    ")\n",
    "\n",
    "print(f\"Training set: {X_train.shape[0]} samples\")\n",
    "print(f\"Testing set: {X_test.shape[0]} samples\")\n",
    "\n",
    "# Check class distribution\n",
    "print(\"\\nClass distribution:\")\n",
    "print(f\"Training set: {pd.Series(y_train).value_counts(normalize=True).round(3) * 100}%\")\n",
    "print(f\"Testing set: {pd.Series(y_test).value_counts(normalize=True).round(3) * 100}%\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d709ef9e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Defining Base Models:\n",
      "Evaluating 8 base models:\n",
      "- Logistic Regression\n",
      "- Random Forest\n",
      "- Gradient Boosting\n",
      "- SVM\n",
      "- KNN\n",
      "- Decision Tree\n",
      "- Naive Bayes\n",
      "- XGBoost\n"
     ]
    }
   ],
   "source": [
    "# 3. Define Base Models\n",
    "\n",
    "print(\"\\nDefining Base Models:\")\n",
    "\n",
    "# Define a list of models to evaluate\n",
    "models = {\n",
    "    'Logistic Regression': LogisticRegression(max_iter=1000, random_state=42),\n",
    "    'Random Forest': RandomForestClassifier(n_estimators=100, random_state=42),\n",
    "    'Gradient Boosting': GradientBoostingClassifier(random_state=42),\n",
    "    'SVM': SVC(probability=True, random_state=42),\n",
    "    'KNN': KNeighborsClassifier(n_neighbors=5),\n",
    "    'Decision Tree': DecisionTreeClassifier(random_state=42),\n",
    "    'Naive Bayes': GaussianNB(),\n",
    "    'XGBoost': XGBClassifier(random_state=42)\n",
    "}\n",
    "\n",
    "print(f\"Evaluating {len(models)} base models:\")\n",
    "for name in models.keys():\n",
    "    print(f\"- {name}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2fc48303",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Evaluating Base Models with Cross-Validation:\n",
      "\n",
      "Evaluating Logistic Regression...\n",
      "Accuracy: 0.8233 ± 0.0274\n",
      "Precision: 0.8202 ± 0.0426\n",
      "Recall: 0.8329 ± 0.0376\n",
      "F1 Score: 0.8253 ± 0.0251\n",
      "\n",
      "Evaluating Random Forest...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hp\\AppData\\Local\\Temp\\ipykernel_2340\\3862323159.py:36: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  results = pd.concat([results, pd.DataFrame({\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.8921 ± 0.0229\n",
      "Precision: 0.8844 ± 0.0230\n",
      "Recall: 0.9030 ± 0.0384\n",
      "F1 Score: 0.8931 ± 0.0236\n",
      "\n",
      "Evaluating Gradient Boosting...\n",
      "Accuracy: 0.8853 ± 0.0191\n",
      "Precision: 0.8847 ± 0.0204\n",
      "Recall: 0.8868 ± 0.0290\n",
      "F1 Score: 0.8855 ± 0.0195\n",
      "\n",
      "Evaluating SVM...\n",
      "Accuracy: 0.8637 ± 0.0172\n",
      "Precision: 0.8502 ± 0.0213\n",
      "Recall: 0.8841 ± 0.0248\n",
      "F1 Score: 0.8666 ± 0.0170\n",
      "\n",
      "Evaluating KNN...\n",
      "Accuracy: 0.8502 ± 0.0237\n",
      "Precision: 0.8282 ± 0.0144\n",
      "Recall: 0.8843 ± 0.0451\n",
      "F1 Score: 0.8549 ± 0.0255\n",
      "\n",
      "Evaluating Decision Tree...\n",
      "Accuracy: 0.8435 ± 0.0222\n",
      "Precision: 0.8348 ± 0.0193\n",
      "Recall: 0.8572 ± 0.0324\n",
      "F1 Score: 0.8456 ± 0.0225\n",
      "\n",
      "Evaluating Naive Bayes...\n",
      "Accuracy: 0.7693 ± 0.0386\n",
      "Precision: 0.7940 ± 0.0555\n",
      "Recall: 0.7331 ± 0.0503\n",
      "F1 Score: 0.7608 ± 0.0398\n",
      "\n",
      "Evaluating XGBoost...\n",
      "Accuracy: 0.8934 ± 0.0206\n",
      "Precision: 0.8862 ± 0.0158\n",
      "Recall: 0.9030 ± 0.0312\n",
      "F1 Score: 0.8944 ± 0.0210\n",
      "\n",
      "Model Rankings by F1 Score:\n",
      "                 Model  Accuracy  Precision    Recall        F1  Std_Accuracy\n",
      "0              XGBoost  0.893406   0.886234  0.902991  0.894367      0.020557\n",
      "1        Random Forest  0.892064   0.884370  0.903027  0.893136      0.022863\n",
      "2    Gradient Boosting  0.885298   0.884717  0.886811  0.885493      0.019056\n",
      "3                  SVM  0.863713   0.850203  0.884144  0.866573      0.017170\n",
      "4                  KNN  0.850236   0.828198  0.884252  0.854862      0.023697\n",
      "5        Decision Tree  0.843479   0.834771  0.857189  0.845608      0.022174\n",
      "6  Logistic Regression  0.823263   0.820213  0.832937  0.825313      0.027420\n",
      "7          Naive Bayes  0.769264   0.794026  0.733117  0.760821      0.038568\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hp\\AppData\\Local\\Temp\\ipykernel_2340\\3862323159.py:61: FutureWarning: \n",
      "\n",
      "Passing `palette` without assigning `hue` is deprecated and will be removed in v0.14.0. Assign the `x` variable to `hue` and set `legend=False` for the same effect.\n",
      "\n",
      "  sns.barplot(x=list(models.keys()), y=metrics['Accuracy'], palette='viridis')\n",
      "C:\\Users\\hp\\AppData\\Local\\Temp\\ipykernel_2340\\3862323159.py:69: FutureWarning: \n",
      "\n",
      "Passing `palette` without assigning `hue` is deprecated and will be removed in v0.14.0. Assign the `x` variable to `hue` and set `legend=False` for the same effect.\n",
      "\n",
      "  sns.barplot(x=list(models.keys()), y=metrics['Precision'], palette='viridis')\n",
      "C:\\Users\\hp\\AppData\\Local\\Temp\\ipykernel_2340\\3862323159.py:77: FutureWarning: \n",
      "\n",
      "Passing `palette` without assigning `hue` is deprecated and will be removed in v0.14.0. Assign the `x` variable to `hue` and set `legend=False` for the same effect.\n",
      "\n",
      "  sns.barplot(x=list(models.keys()), y=metrics['Recall'], palette='viridis')\n",
      "C:\\Users\\hp\\AppData\\Local\\Temp\\ipykernel_2340\\3862323159.py:85: FutureWarning: \n",
      "\n",
      "Passing `palette` without assigning `hue` is deprecated and will be removed in v0.14.0. Assign the `x` variable to `hue` and set `legend=False` for the same effect.\n",
      "\n",
      "  sns.barplot(x=list(models.keys()), y=metrics['F1'], palette='viridis')\n"
     ]
    }
   ],
   "source": [
    "# 4. Evaluate Base Models with Cross-Validation\n",
    "\n",
    "print(\"\\nEvaluating Base Models with Cross-Validation:\")\n",
    "\n",
    "# Define cross-validation strategy\n",
    "cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "# Metrics to evaluate\n",
    "metrics = {\n",
    "    'Accuracy': [],\n",
    "    'Precision': [],\n",
    "    'Recall': [],\n",
    "    'F1': []\n",
    "}\n",
    "\n",
    "# Results dataframe\n",
    "results = pd.DataFrame(columns=['Model', 'Accuracy', 'Precision', 'Recall', 'F1', 'Std_Accuracy'])\n",
    "\n",
    "# Evaluate each model with cross-validation\n",
    "for name, model in models.items():\n",
    "    print(f\"\\nEvaluating {name}...\")\n",
    "    \n",
    "    # Calculate cross-validation scores\n",
    "    accuracy = cross_val_score(model, X_train, y_train, cv=cv, scoring='accuracy')\n",
    "    precision = cross_val_score(model, X_train, y_train, cv=cv, scoring='precision')\n",
    "    recall = cross_val_score(model, X_train, y_train, cv=cv, scoring='recall')\n",
    "    f1 = cross_val_score(model, X_train, y_train, cv=cv, scoring='f1')\n",
    "    \n",
    "    # Print results\n",
    "    print(f\"Accuracy: {accuracy.mean():.4f} ± {accuracy.std():.4f}\")\n",
    "    print(f\"Precision: {precision.mean():.4f} ± {precision.std():.4f}\")\n",
    "    print(f\"Recall: {recall.mean():.4f} ± {recall.std():.4f}\")\n",
    "    print(f\"F1 Score: {f1.mean():.4f} ± {f1.std():.4f}\")\n",
    "    \n",
    "    # Add to results dataframe\n",
    "    results = pd.concat([results, pd.DataFrame({\n",
    "        'Model': [name],\n",
    "        'Accuracy': [accuracy.mean()],\n",
    "        'Precision': [precision.mean()],\n",
    "        'Recall': [recall.mean()],\n",
    "        'F1': [f1.mean()],\n",
    "        'Std_Accuracy': [accuracy.std()]\n",
    "    })], ignore_index=True)\n",
    "    \n",
    "    # Store results for plotting\n",
    "    metrics['Accuracy'].append(accuracy.mean())\n",
    "    metrics['Precision'].append(precision.mean())\n",
    "    metrics['Recall'].append(recall.mean())\n",
    "    metrics['F1'].append(f1.mean())\n",
    "\n",
    "# Sort results by F1 score\n",
    "results = results.sort_values('F1', ascending=False).reset_index(drop=True)\n",
    "print(\"\\nModel Rankings by F1 Score:\")\n",
    "print(results)\n",
    "\n",
    "# Plot model comparison\n",
    "plt.figure(figsize=(14, 10))\n",
    "\n",
    "# Accuracy comparison\n",
    "plt.subplot(2, 2, 1)\n",
    "sns.barplot(x=list(models.keys()), y=metrics['Accuracy'], palette='viridis')\n",
    "plt.title('Model Accuracy Comparison', fontsize=14)\n",
    "plt.ylabel('Accuracy', fontsize=12)\n",
    "plt.xticks(rotation=45, ha='right')\n",
    "plt.ylim(0.65, 0.85)\n",
    "\n",
    "# Precision comparison\n",
    "plt.subplot(2, 2, 2)\n",
    "sns.barplot(x=list(models.keys()), y=metrics['Precision'], palette='viridis')\n",
    "plt.title('Model Precision Comparison', fontsize=14)\n",
    "plt.ylabel('Precision', fontsize=12)\n",
    "plt.xticks(rotation=45, ha='right')\n",
    "plt.ylim(0.65, 0.85)\n",
    "\n",
    "# Recall comparison\n",
    "plt.subplot(2, 2, 3)\n",
    "sns.barplot(x=list(models.keys()), y=metrics['Recall'], palette='viridis')\n",
    "plt.title('Model Recall Comparison', fontsize=14)\n",
    "plt.ylabel('Recall', fontsize=12)\n",
    "plt.xticks(rotation=45, ha='right')\n",
    "plt.ylim(0.65, 0.85)\n",
    "\n",
    "# F1 Score comparison\n",
    "plt.subplot(2, 2, 4)\n",
    "sns.barplot(x=list(models.keys()), y=metrics['F1'], palette='viridis')\n",
    "plt.title('Model F1 Score Comparison', fontsize=14)\n",
    "plt.ylabel('F1 Score', fontsize=12)\n",
    "plt.xticks(rotation=45, ha='right')\n",
    "plt.ylim(0.65, 0.85)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('C:/Users/hp/Desktop/diabetes-analysis-project/visuals/static/model_comparison.png')\n",
    "plt.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "714f7a21",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Detailed Evaluation of Top 3 Models:\n",
      "Top 3 models for detailed evaluation: ['XGBoost', 'Random Forest', 'Gradient Boosting']\n",
      "\n",
      "Detailed evaluation of XGBoost:\n",
      "Test Accuracy: 0.9032\n",
      "Test Precision: 0.8571\n",
      "Test Recall: 0.9677\n",
      "Test F1 Score: 0.9091\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.84      0.90       124\n",
      "           1       0.86      0.97      0.91       124\n",
      "\n",
      "    accuracy                           0.90       248\n",
      "   macro avg       0.91      0.90      0.90       248\n",
      "weighted avg       0.91      0.90      0.90       248\n",
      "\n",
      "\n",
      "Detailed evaluation of Random Forest:\n",
      "Test Accuracy: 0.9073\n",
      "Test Precision: 0.8741\n",
      "Test Recall: 0.9516\n",
      "Test F1 Score: 0.9112\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.86      0.90       124\n",
      "           1       0.87      0.95      0.91       124\n",
      "\n",
      "    accuracy                           0.91       248\n",
      "   macro avg       0.91      0.91      0.91       248\n",
      "weighted avg       0.91      0.91      0.91       248\n",
      "\n",
      "\n",
      "Detailed evaluation of Gradient Boosting:\n",
      "Test Accuracy: 0.8911\n",
      "Test Precision: 0.8702\n",
      "Test Recall: 0.9194\n",
      "Test F1 Score: 0.8941\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.86      0.89       124\n",
      "           1       0.87      0.92      0.89       124\n",
      "\n",
      "    accuracy                           0.89       248\n",
      "   macro avg       0.89      0.89      0.89       248\n",
      "weighted avg       0.89      0.89      0.89       248\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 5. Detailed Evaluation of Top 3 Models\n",
    "\n",
    "print(\"\\n🔍 Detailed Evaluation of Top 3 Models:\")\n",
    "\n",
    "# Select top 3 models based on F1 score\n",
    "top_models = results.head(3)['Model'].tolist()\n",
    "print(f\"Top 3 models for detailed evaluation: {top_models}\")\n",
    "\n",
    "# Train and evaluate each top model\n",
    "for model_name in top_models:\n",
    "    print(f\"\\nDetailed evaluation of {model_name}:\")\n",
    "    model = models[model_name]\n",
    "    \n",
    "    # Train the model\n",
    "    model.fit(X_train, y_train)\n",
    "    \n",
    "    # Predict on test set\n",
    "    y_pred = model.predict(X_test)\n",
    "    y_pred_proba = model.predict_proba(X_test)[:, 1]\n",
    "    \n",
    "    # Calculate metrics\n",
    "    acc = accuracy_score(y_test, y_pred)\n",
    "    prec = precision_score(y_test, y_pred)\n",
    "    rec = recall_score(y_test, y_pred)\n",
    "    f1 = f1_score(y_test, y_pred)\n",
    "    \n",
    "    print(f\"Test Accuracy: {acc:.4f}\")\n",
    "    print(f\"Test Precision: {prec:.4f}\")\n",
    "    print(f\"Test Recall: {rec:.4f}\")\n",
    "    print(f\"Test F1 Score: {f1:.4f}\")\n",
    "    \n",
    "    # Classification Report\n",
    "    print(\"\\nClassification Report:\")\n",
    "    print(classification_report(y_test, y_pred))\n",
    "    \n",
    "    # Plot confusion matrix\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    cm = confusion_matrix(y_test, y_pred)\n",
    "    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', cbar=False)\n",
    "    plt.title(f'Confusion Matrix - {model_name}', fontsize=14)\n",
    "    plt.ylabel('True Label', fontsize=12)\n",
    "    plt.xlabel('Predicted Label', fontsize=12)\n",
    "    plt.savefig(f'C:/Users/hp/Desktop/diabetes-analysis-project/visuals/static/confusion_matrix_{model_name.replace(\" \", \"_\").lower()}.png')\n",
    "    plt.close()\n",
    "    \n",
    "    # Plot ROC curve\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    fpr, tpr, _ = roc_curve(y_test, y_pred_proba)\n",
    "    roc_auc = auc(fpr, tpr)\n",
    "    \n",
    "    plt.plot(fpr, tpr, color='darkorange', lw=2, label=f'ROC curve (area = {roc_auc:.2f})')\n",
    "    plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')\n",
    "    plt.xlim([0.0, 1.0])\n",
    "    plt.ylim([0.0, 1.05])\n",
    "    plt.xlabel('False Positive Rate', fontsize=12)\n",
    "    plt.ylabel('True Positive Rate', fontsize=12)\n",
    "    plt.title(f'ROC Curve - {model_name}', fontsize=14)\n",
    "    plt.legend(loc=\"lower right\")\n",
    "    plt.savefig(f'C:/Users/hp/Desktop/diabetes-analysis-project/visuals/static/roc_curve_{model_name.replace(\" \", \"_\").lower()}.png')\n",
    "    plt.close()\n",
    "    \n",
    "    # Plot Precision-Recall curve\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    precision, recall, _ = precision_recall_curve(y_test, y_pred_proba)\n",
    "    pr_auc = auc(recall, precision)\n",
    "    \n",
    "    plt.plot(recall, precision, color='darkorange', lw=2, label=f'PR curve (area = {pr_auc:.2f})')\n",
    "    plt.xlim([0.0, 1.0])\n",
    "    plt.ylim([0.0, 1.05])\n",
    "    plt.xlabel('Recall', fontsize=12)\n",
    "    plt.ylabel('Precision', fontsize=12)\n",
    "    plt.title(f'Precision-Recall Curve - {model_name}', fontsize=14)\n",
    "    plt.legend(loc=\"lower left\")\n",
    "    plt.savefig(f'C:/Users/hp/Desktop/diabetes-analysis-project/visuals/static/pr_curve_{model_name.replace(\" \", \"_\").lower()}.png')\n",
    "    plt.close()\n",
    "    \n",
    "    # Save the model\n",
    "    joblib.dump(model, f'C:/Users/hp/Desktop/diabetes-analysis-project/outputs/models/{model_name.replace(\" \", \"_\").lower()}.pkl')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "828967da",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Feature Importance Analysis:\n",
      "\n",
      "Feature Importance for XGBoost:\n",
      "                     Feature  Importance\n",
      "4                    Insulin    0.370307\n",
      "10            Age_BMI_Factor    0.109198\n",
      "8        Diabetes_Risk_Index    0.109029\n",
      "3              SkinThickness    0.070951\n",
      "7                        Age    0.065667\n",
      "6   DiabetesPedigreeFunction    0.061496\n",
      "5                        BMI    0.055311\n",
      "9        Insulin_Sensitivity    0.049320\n",
      "1                    Glucose    0.044270\n",
      "0                Pregnancies    0.033671\n",
      "2              BloodPressure    0.030780\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hp\\AppData\\Local\\Temp\\ipykernel_2340\\2594990994.py:19: FutureWarning: \n",
      "\n",
      "Passing `palette` without assigning `hue` is deprecated and will be removed in v0.14.0. Assign the `y` variable to `hue` and set `legend=False` for the same effect.\n",
      "\n",
      "  sns.barplot(x='Importance', y='Feature', data=feature_importance, palette='viridis')\n"
     ]
    }
   ],
   "source": [
    "# 6. Feature Importance for Top Model\n",
    "\n",
    "print(\"\\n🔍 Feature Importance Analysis:\")\n",
    "best_model_name = results.iloc[0]['Model']\n",
    "best_model = models[best_model_name]\n",
    "\n",
    "# Get feature importance if available\n",
    "if hasattr(best_model, 'feature_importances_'):\n",
    "    feature_importance = pd.DataFrame({\n",
    "        'Feature': X.columns,\n",
    "        'Importance': best_model.feature_importances_\n",
    "    }).sort_values('Importance', ascending=False)\n",
    "    \n",
    "    print(f\"\\nFeature Importance for {best_model_name}:\")\n",
    "    print(feature_importance)\n",
    "    \n",
    "    # Plot feature importance\n",
    "    plt.figure(figsize=(12, 8))\n",
    "    sns.barplot(x='Importance', y='Feature', data=feature_importance, palette='viridis')\n",
    "    plt.title(f'Feature Importance - {best_model_name}', fontsize=16)\n",
    "    plt.xlabel('Importance', fontsize=14)\n",
    "    plt.ylabel('Feature', fontsize=14)\n",
    "    plt.tight_layout()\n",
    "    plt.savefig('C:/Users/hp/Desktop/diabetes-analysis-project/visuals/static/feature_importance.png')\n",
    "    plt.close()\n",
    "\n",
    "elif best_model_name == 'Logistic Regression':\n",
    "    # For logistic regression, use coefficients as importance\n",
    "    feature_importance = pd.DataFrame({\n",
    "        'Feature': X.columns,\n",
    "        'Coefficient': best_model.coef_[0]\n",
    "    }).sort_values('Coefficient', ascending=False)\n",
    "    \n",
    "    print(f\"\\nFeature Coefficients for {best_model_name}:\")\n",
    "    print(feature_importance)\n",
    "    \n",
    "    # Plot feature coefficients\n",
    "    plt.figure(figsize=(12, 8))\n",
    "    sns.barplot(x='Coefficient', y='Feature', data=feature_importance, palette='viridis')\n",
    "    plt.title(f'Feature Coefficients - {best_model_name}', fontsize=16)\n",
    "    plt.xlabel('Coefficient', fontsize=14)\n",
    "    plt.ylabel('Feature', fontsize=14)\n",
    "    plt.axvline(x=0, color='red', linestyle='--')\n",
    "    plt.tight_layout()\n",
    "    plt.savefig('C:/Users/hp/Desktop/diabetes-analysis-project/visuals/static/feature_coefficients.png')\n",
    "    plt.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "57f5e2e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "📝 Model Development Summary:\n",
      "\n",
      "Model Development Summary:\n",
      "\n",
      "1. Best Performing Model:\n",
      "   - Name: XGBoost\n",
      "   - Accuracy: 0.8934\n",
      "   - Precision: 0.8862\n",
      "   - Recall: 0.9030\n",
      "   - F1 Score: 0.8944\n",
      "\n",
      "2. Top 3 Models:\n",
      "               Model       F1\n",
      "          XGBoost 0.894367\n",
      "    Random Forest 0.893136\n",
      "Gradient Boosting 0.885493\n",
      "\n",
      "3. All models have been saved to the '../../outputs/models/' directory\n",
      "\n",
      "4. Key Findings:\n",
      "   - XGBoost performs best among all models\n",
      "   - Most important features: ['Insulin', 'Age_BMI_Factor', 'Diabetes_Risk_Index']\n",
      "   - Model evaluation metrics and visualizations created\n",
      "\n",
      "Next Steps:\n",
      "- Fine-tune the best model with hyperparameter optimization\n",
      "- Evaluate model performance on different subsets of the data\n",
      "- Create an ensemble of top-performing models\n",
      "- Develop a prediction system for diabetes risk assessment\n",
      "\n",
      "\n",
      "Model development complete! Models saved to '../../outputs/models/' directory\n"
     ]
    }
   ],
   "source": [
    "# 7. Model Development Summary\n",
    "# -----------------------------------------------------\n",
    "\n",
    "print(\"\\n📝 Model Development Summary:\")\n",
    "best_model_metrics = results.iloc[0]\n",
    "print(f\"\"\"\n",
    "Model Development Summary:\n",
    "\n",
    "1. Best Performing Model:\n",
    "   - Name: {best_model_metrics['Model']}\n",
    "   - Accuracy: {best_model_metrics['Accuracy']:.4f}\n",
    "   - Precision: {best_model_metrics['Precision']:.4f}\n",
    "   - Recall: {best_model_metrics['Recall']:.4f}\n",
    "   - F1 Score: {best_model_metrics['F1']:.4f}\n",
    "\n",
    "2. Top 3 Models:\n",
    "   {results[['Model', 'F1']].head(3).to_string(index=False)}\n",
    "\n",
    "3. All models have been saved to the '../../outputs/models/' directory\n",
    "\n",
    "4. Key Findings:\n",
    "   - {best_model_metrics['Model']} performs best among all models\n",
    "   - Most important features: {feature_importance['Feature'].iloc[:3].tolist() if 'feature_importance' in locals() else 'N/A'}\n",
    "   - Model evaluation metrics and visualizations created\n",
    "\n",
    "Next Steps:\n",
    "- Fine-tune the best model with hyperparameter optimization\n",
    "- Evaluate model performance on different subsets of the data\n",
    "- Create an ensemble of top-performing models\n",
    "- Develop a prediction system for diabetes risk assessment\n",
    "\"\"\")\n",
    "\n",
    "print(\"\\nModel development complete! Models saved to '../../outputs/models/' directory\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "996b24f3",
   "metadata": {},
   "source": [
    "# Model Development Summary:\n",
    "\n",
    "### Model Development Summary:\n",
    "\n",
    "## 1. Best Performing Model:\n",
    "   - Name: XGBoost\n",
    "   - Accuracy: 0.8934\n",
    "   - Precision: 0.8862\n",
    "   - Recall: 0.9030\n",
    "\n",
    "\n",
    "## 2. Top 3 Models:\n",
    "               Model  F1\n",
    "          XGBoost 0.894367\n",
    "    Random Forest 0.893136\n",
    "Gradient Boosting 0.885493\n",
    "\n",
    "## 3. All models have been saved to the '../../outputs/models/' directory\n",
    "\n",
    "## 4. Key Findings:\n",
    "   - XGBoost performs best among all models\n",
    "   - Most important features: ['Insulin', 'Age_BMI_Factor', 'Diabetes_Risk_Index']\n",
    "   - Model evaluation metrics and visualizations created\n",
    "...\n",
    "- Develop a prediction system for diabetes risk assessment\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
